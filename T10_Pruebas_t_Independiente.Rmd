---
title: "T10 Pruebas t Independiente"
output:
  html_document:
    css: tutorial.css
    fig_caption: yes
    highlight: pygments
#    theme: simplex
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)

```


```{r, echo=FALSE}
library(tidyverse)

rlt_theme <- theme(axis.title.y = element_text(colour="grey20",size=15,face="bold"),
        axis.text.x = element_text(colour="grey20",size=10, face="bold"),
        axis.text.y = element_text(colour="grey20",size=15,face="bold"),  
        axis.title.x = element_text(colour="grey20",size=15,face="bold"))+
  theme(
  # Remove panel border
  panel.border = element_blank(),  
  # Remove panel grid lines
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  # Remove panel background
  panel.background = element_blank(),
  # add thicker border lines
    axis.line.x = element_line(colour = "black", size = 1),
    axis.line.y = element_line(colour = "black", size = 1)
  )

# The palette with grey:
cbPalette1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# The palette with black:
cbPalette2 <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# To use for fills, add
#  scale_fill_manual(values=cbPalette)

# To use for line and point colors, add
  #scale_colour_manual(values=cbPalette)

```



```{r, eval=TRUE, echo=FALSE}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, 
      x)
  } else x
}

#`r colorize("some words in red", "red")`


```

Fecha de la ultima revisión
```{r echo=FALSE}

Sys.Date()
```

```{r, echo=FALSE, fig.show = "hold", out.width = "20%", fig.align = "default"}
knitr::include_graphics(c("Graficos/hex_ggversa.png", "Graficos/hex_error.png"))
```



```{r}

library(car)  # para la prueba de leveneTest

library(RVAideMemoire) # para la prueba de byf.shapiro
```

***

# La prueba t con datos independiente

Una de las pruebas más común es la de comparar dos grupos y evaluar si los promedios de estos grupos son diferentes. Por ejemplo determinar si la edad de los estudiantes una clase es diferentes entre mujeres y hombres.  Evaluar si dos concentraciones de antibiótico resulta en una reducción en el tiempo de infección de una enfermedad especifica. NOTA IMPORTANTE: los datos provienen de diferentes individuos, solamente un valor por individuo. Recuerda que en la prueba anterior de la prueba de t con datos pareados tenemos más de un dato por cada persona/individuo/unidad de muestreo.  


Datos


Producimos un set de datos de diferentes personas, con las siguientes variables, el genero, la distancia (dist) viajada por estudiantes que van a la universidad de UPR-Utuado y UPR-Bayamón. 

```{r, attr.source='.numberLines'}
genero=c("m","f","f","f",
    "f","f","f","f","f",
    "m","f","m","f","f",
    "m","m","f","f","f",
    "f","f","m", "f","m",
    "m","f", "f", "f","f",
    "f","m","m","m","f",
    "f","f")
dist=c(92,50,75,55,
       30, 40,60,35,65,
       45, 65, 80,60,67,
       98,88,60,20,49,
       45, 19,27,20,34,
       30,45, 35,26, 24, 
       34,12, 26, 21, 25, 
       15, 22)
muni=c("utuado","utuado","utuado","utuado",
      "utuado","utuado","utuado","utuado","utuado",
      "utuado","utuado","utuado","utuado","utuado",
      "utuado","utuado","utuado","utuado","utuado",
      "bayamón","bayamón","bayamón","bayamón","bayamón",
      "bayamón","bayamón","bayamón","bayamón","bayamón",
      "bayamón","bayamón","bayamón","bayamón","bayamón",
      "bayamón","bayamón")
```

Unir los datos en un data frame con la función de "data.frame( )"

```{r join lists in a df}
viajes=data.frame(genero,dist,muni)
head(viajes)
tail(viajes)
```

***

Hacer un  gráfico de los datos.  Si calculamos el promedio de todos los valores de "Y" y lo visualizamos, vemos que muchos de los valores del municipio "bayamón" son muy por debajo los valores de la linea y muchos de los valores del municipio "utuado" son muy por encima.    

```{r plot}

mean_dist=mean(viajes$dist)

ggplot(viajes, aes(muni, dist, colour=muni))+
  geom_jitter(width = .2)+
  geom_hline(yintercept = mean_dist)
```

***

## Las hipótesis

### La Nula
 + Ho: es que la distancia promedia que viaja los estudiantes es igual irrelevante del municipio donde estudian
 + Ho: Promerio_1 = Promedio_2 o mejor 
 + Ho: $\overline{x}_1=\overline{x}_2$

### La Alterna
 + Ha: es que la distancia promedia que viaja de los estudiantes no es igual (depende del municipio donde provienen) 
 + Ha: $\overline{x}_1\ne\overline{x}_2$


Otra alternativa para visualizar es observar la diferencias entre el valor de la "y's" y del promedio de esa variable, o sea los residuales (la diferencia entre el promedio y el valor se llaman los **residuales**. `r colorize("Nota que esto aparece a la gráfica de residuales de la regresión lineal", "blue")`.


```{r}
plot(1:36, dist, ylim=c(0, 100), ylab="y", xlab = "order", pch=21, bg="red")
abline(h=mean(dist), col="blue")
for(i in 1:36) lines(c(i,i), c(mean(dist), dist[i]), col="green")
```


Ahora vamos a separar la gráfica y visualizar los residuales por grupo, en otra palabra, cual son los residuales entre los valores y el promedio dentro de los mismos grupos. Se observa en este caso que hay menos varianza entre los valores de un mismo grupo. Note que en el grupo de `r colorize("**bayamón**", "blue")` que los valores son bastante cerca del promedio de este grupo en adición que los valores de `r colorize("**utuado**", "red")` estan más cerca de su promedio.  Compara los residuales con la gráfica anterior.   


```{r}
plot(1:36, dist, ylim=c(0, 100), ylab="y", xlab = "order", pch=21, bg="red")
abline(h=mean(dist[muni=="bayamón"]), col="blue")
abline(h=mean(dist[muni=="utuado"]), col="red")
index<- 1:length(dist)
for (i in 1:length(index)){
  if(muni[i]=="bayamón")
    lines(c(index[i], index[i]), c(mean(dist[muni=="bayamón"]),dist[i]), col="blue")
  else
    lines(c(index[i], index[i]), c(mean(dist[muni=="utuado"]),dist[i]), col="red")
}
```

***

# Comparación de dos grupos

Hay diferentes acercamiento para hacer la **prueba de t** (t-test). Usaremos la más conocida. Donde comparamos el promedio de un grupo con el promedio de otro grupo, y determinar si no hay diferencias entre los grupos, la diferencias entre uno y el otro debería acercarse a cero si no hay diferencia entre los grupos. Hay que tomar en cuenta la cantidad de varianza/error en los análisis. Esto se toma encuenta considerando el error estándar en la formula siguiente. 

$$t= \frac{\bar{X_1}-\bar{X_2}}{SE}$$

Más especifico la estadistica de **t** y el **error estándar** se calcula de la siguiente forma.  

$$t=\frac{\bar{X_1}-\bar{X_2}}{\sqrt{\frac{{s}^{2}_p}{n_1}+\frac{{s}^{2}_p}{n_2}}}$$


Donde la varianza ponderada (Weighted variance, ${s}^{2}_p$), es un indice de la varianza de los dos grupos tomando en cuenta el tamaño de muestra de cada grupo.  Note que la varianza $s^2$ de cada grupo es multiplicado por (n-1) para sea "ponderada" basado en el tamaño de muestra por grupo. Por consecuencia un grupo que tiene pocos datos, "n", su varianza tendrá menos peso en los análisis.  

$${s}^{2}_p = \frac{(n_1-1){s}^{2}_1+(n_2-1){s}^{2}_2}{n_1+n_2-2}$$

***


### La prueba t

Mi primera prueba para comparar el promedio entre dos grupos.  Se usa la prueba de "t.test" (t-test).  

La estructura de la prueba es la siguiente (lo mínimo)

t.test(variable_de_respuesta ~ variable_de_grupo, dataframe)

La hipótesis nula:
 Ho: la distancia viajado por la gente de la gente de los dos municipios es igual (el valor de "p" sera major de 0.05)
 
La hipótesis alterna:
 Ha: la distancia viajado por la gente no es igual por la gente de los dos municipios (el valor de "p" sera menor de 0.05 )



```{r t.test}
model=t.test(dist~muni,data=viajes, paired=FALSE)
model
```



```{r}
gender=c("m", "m", "f", "f", "m", 
         "f","f","m", "f", "f", "f")

dist=c(10,20, 11, 40, 19, 
       8.1, 203, 4.4, 16, 29, 19)

df=data.frame(gender, dist)
head(df)

model2=t.test(dist~gender, data=df, paired=FALSE)
model2
```


```{r}
padres=c("p", "m" , "p", "m", "p","m",
         "p","m", "p","m", "p","m",
         "p","m", "p","m", "p","m", 
         "p", "m")

Hermanos= c(2, 1,2,2,2,3,
            3,2,4,1,2,1,
            2,1,5,2,5,3, 
            12, 2)


```





***

## Gráficar el promedio y el intervalo de confianza

Graficar los datos con el promedio y el intervalo de confianza da un resumen de la estadística de forma visual, lo que se visualiza es el promedio y el intervalo de 95%.  Nota que se usa la función en ggplot2 de **stat_summary(fun.data = mean_cl_normal)**, esto quiere decir que se esta calculando los valores ASUMIENDO una distribución normal de los datos. 

```{r graph summary stats}
ggplot(df, aes(gender, dist))+
 stat_summary(fun.data = mean_cl_normal, geom = "pointrange")

```

***

# Pruebas de normalidades

## Visualización de los datos

Siempre se debería producir un gráfico de los datos para tener una idea de si los datos cumple con los supuestos de las pruebas. 
Ahora ver las distribución de frecuencia por municipio. Si los datos tuviese una distribución **perfecta** normal, se obtendría una distribición en forma de campana.   Primero NO se debería esperar este tipo de distribución cuando tenemos pocos datos.  

```{r}
ggplot(viajes, aes(dist, fill=muni))+
  geom_histogram(colour="white")+
  facet_grid(~muni)
```


***



## Shapiro-Wilks: Prueba de normalidad 

La prueba de Shapiro-Wilks fue publicado por Sanuel S. Shapiro and Martin Wilk en 1965.  La prueba de Shapiro_Wilks es una prueba para determinar si lo datos **provienen**  de una distribución normal. La hipótesis NULA es que los datos provienen de una distribución normal, por consecuencia cuando uno acepta la hipótesis nula (p > 0.05) es que **no hay evidencia de sugerir que los datos no provienen de una distribución normal**. Es solamente cuando el valor de p es menor de 0.05 que uno rechaza la hipótesis y hay evidencia que los datos no provienen de una distribución normal.  

Problema con la prueba cuando la muestra es grande

Es típico que cuando uno tiene muchos muchos datos uno puede encontrar diferencias significativas entres los grupos, en este caso cuando hay muchos datos la prueba pudiese sugerir que los datos no tienen distribución normal cuando en realidad se esta detectando diferenciales triviales.  En la prueba abajo se sugiere de NO utilizarla si tiene mayor de 2000 datos.   Al contrario cuando tenga muy pocos datos (n<50) no se debería usar la prueba de Shapiro-Wilks.



### Evaluar la 

```{r shapiro test}
shapiro.test(viajes$dist)
```

### Metodo #1: shapiro.test()




```{r SW test}
# Normality test by group
# Method 1 
shapiro.test(viajes$dist)
shapiro.test(viajes$dist[viajes$muni=="utuado"])
shapiro.test(viajes$dist[viajes$muni=="bayamón"])
```


### Method 2: byf.shapiro()

Aqui es una prueba más sensilla para hacer para comprobar que los grupos tienen distribución normal. `r colorize("Tiene que usar la libreria 'RVAideMemoire' y la función byf.shapiro( )", "red")` . 

Recuerda, que si el valor de p es mayor de 0.05, se asume que los datos tienen una distribución normal, si es menor de 0.05 se asume que no es normal.   

Nota la oragnización de la prueba, es como la de la t.test( )

byf.shapiro(variable_de_respuesta ~ variable_de_grupo, dataframe)


```{r SW2}
# de la libreria de (RVAideMemoire)

byf.shapiro(dist~muni, viajes)

```


***

# Prueba de Igualdad de Varianza

http://www.cookbook-r.com/Statistical_analysis/Homogeneity_of_variance/

Presento 3 alternativas para la prueba de igualdad de varianza. 

Las pruebas siguientes tambiens se llaman pruebas de homoscedasticidad de varianza, o sea que la varianza en los diferentes grupos es igual. por consecuencia la hipotesis nnula es que la varianza del primer grupo es igual a la varianza del segundo grupo (para una prueba t).  Nota aqui es es importante donde se encuenta el promedio o la mediana, lo que es importante es la distribución de los datos. 

Homogemeidad de varianza
$$H_o:  {s}^{2}_1 = {s}^{2}_2$$

y la hipotesis alterna

$$H_a:  {s}^{2}_1 \neq  {s}^{2}_2$$


Cuando los datos no cumple con distribución igualdad de varianza se dice que los datos heteroscedasticidad.  

1. Bartlett's test of equality of variance
  Los datos tienen que cumplir con la distribución normal para usar esta prueba, si no cumple tendra una mayor probabilidad de rechazar la hipotesis nula.
2. Levene's Test for equality of variance
  La prueba de Levene los datos no son tan sensitivo a la distribución normal, pero no deberia tampoco ser muy diferente de ella. 
3. Fligner-Killeen Test for equality of Variance
  La prueba de Fligner-Killeen los datos NO tiene que cumplir con distribición normal y es una prueba robusta cuando hay datos sesgados (outliers).  



## La prueba de Bartlett 

```{r}
bartlett.test(dist~muni, data=viajes)
```

## Prueba de Levene para igualdad de Varianza
 - similar to Bartlett's test

```{r}

leveneTest(dist~muni, data=viajes)
```


 
## Prueba de Fligner-Killeen para igualdad de Varianza

- good when the distribution are not normal

```{r}
fligner.test(dist~muni, data=viajes)
```


1. Ejercicio 


```{r my students}
sex=c("f","f","f","f","f",
      "f","f","f","f","f",
      "f",
      "m","m","m",
      "m","m","m")
kids=c(0, 1, 2, 1, 1,
       4, 4, 2, 0, 10,
       2,
       80, 24,
       32, 22, 22,15)

futurePR=data.frame(sex,kids)

head(futurePR)

model2=t.test(kids~sex, data=futurePR)
model2

byf.shapiro(kids~sex, futurePR)
```








